# ArgoCD CRON Jobs for Grocery Genie Data Loading

## ğŸ¯ **Overview**

This document describes the ArgoCD-managed CRON job system that automatically loads grocery data from `./data/` directories into staging and production databases daily at 11:30 PM EST.

## ğŸ—ï¸ **Architecture**

### **ArgoCD Applications**
- **Staging**: `grocery-genie-staging` â†’ `kubernetes/staging/`
- **Production**: `grocery-genie-production` â†’ `kubernetes/production/`

### **CRON Job Schedule (EST)**
```
11:30 PM - CVS Data Loader
11:35 PM - Costco Data Loader  
11:40 PM - Walmart Data Loader
11:45 PM - Publix Data Loader
11:50 PM - Other Purchases Loader
```

## ğŸ“ **Data Flow**

### **Data Directories**
```
./data/
â”œâ”€â”€ cvs/           # CVS YAML files
â”œâ”€â”€ costco/        # Costco YAML files  
â”œâ”€â”€ walmart/       # Walmart YAML files
â”œâ”€â”€ publix/        # Publix YAML files
â””â”€â”€ other/         # Other purchases YAML files
```

### **Database Tables**
- `cvs_purchases`
- `costco_purchases` 
- `walmart_purchases`
- `publix_purchases`
- `other_purchases`

## ğŸš€ **CRON Job Details**

### **CVS Data Loader**
- **Schedule**: `30 23 * * *` (11:30 PM EST daily)
- **Script**: `src/loaders/cvs_data_loader.py`
- **Data Source**: `./data/cvs/*.yaml`
- **Target Table**: `cvs_purchases`

### **Costco Data Loader**
- **Schedule**: `35 23 * * *` (11:35 PM EST daily)
- **Script**: `src/loaders/yaml_to_database.py`
- **Data Source**: `./data/costco/*.yaml`
- **Target Table**: `costco_purchases`

### **Walmart Data Loader**
- **Schedule**: `40 23 * * *` (11:40 PM EST daily)
- **Script**: `src/loaders/walmart_data_loader.py`
- **Data Source**: `./data/walmart/*.yaml`
- **Target Table**: `walmart_purchases`

### **Publix Data Loader**
- **Schedule**: `45 23 * * *` (11:45 PM EST daily)
- **Script**: `src/loaders/publix_data_processor.py`
- **Data Source**: `./data/publix/*.yaml`
- **Target Table**: `publix_purchases`

### **Other Purchases Loader**
- **Schedule**: `50 23 * * *` (11:50 PM EST daily)
- **Script**: `src/loaders/other_purchases_loader.py`
- **Data Source**: `./data/other/*.yaml`
- **Target Table**: `other_purchases`

## ğŸ”§ **Configuration**

### **Environment Variables**
```yaml
env:
- name: ENV
  value: "staging" | "production"
- name: DB_HOST
  valueFrom:
    configMapKeyRef:
      name: grocery-genie-config
      key: DB_HOST
- name: DB_PORT
  valueFrom:
    configMapKeyRef:
      name: grocery-genie-config
      key: DB_PORT
- name: DB_NAME
  valueFrom:
    configMapKeyRef:
      name: grocery-genie-config
      key: DB_NAME
- name: DB_USER
  valueFrom:
    secretKeyRef:
      name: grocery-genie-secrets
      key: DB_USER
- name: DB_PASSWORD
  valueFrom:
    secretKeyRef:
      name: grocery-genie-secrets
      key: DB_PASSWORD
```

### **Resource Allocation**

#### **Staging Environment**
```yaml
resources:
  requests:
    memory: "256Mi"
    cpu: "100m"
  limits:
    memory: "512Mi"
    cpu: "500m"
```

#### **Production Environment**
```yaml
resources:
  requests:
    memory: "512Mi"
    cpu: "200m"
  limits:
    memory: "1Gi"
    cpu: "1000m"
```

## ğŸ“Š **Monitoring & Logging**

### **Job History**
- **Staging**: 3 successful + 3 failed jobs retained
- **Production**: 5 successful + 5 failed jobs retained

### **CRON Job Policies**
- **Concurrency**: `Forbid` (prevents overlapping jobs)
- **Restart Policy**: `OnFailure`
- **Time Zone**: `America/New_York` (EST)

### **Monitoring Commands**
```bash
# Check CRON job status
kubectl get cronjobs -n staging
kubectl get cronjobs -n production

# Check job history
kubectl get jobs -n staging -l component=data-loader
kubectl get jobs -n production -l component=data-loader

# Check pod logs
kubectl logs -n staging -l retailer=cvs
kubectl logs -n production -l retailer=costco
```

## ğŸ› ï¸ **Deployment**

### **ArgoCD Setup**
1. **Connect Repository** in ArgoCD UI:
   - Repository URL: `https://github.com/tuolden/grocery-genie.git`
   - Username: `tuolden`
   - Password: `******`

2. **Create Applications**:
   - **Staging**: Path `kubernetes/staging/`
   - **Production**: Path `kubernetes/production/`

### **Manual Deployment**
```bash
# Deploy staging CRON jobs
kubectl apply -f kubernetes/staging/cronjob-data-loaders.yaml

# Deploy production CRON jobs  
kubectl apply -f kubernetes/production/cronjob-data-loaders.yaml
```

## ğŸ”„ **Data Processing Workflow**

### **Daily Process**
1. **11:30 PM EST**: CVS data loader processes `./data/cvs/*.yaml`
2. **11:35 PM EST**: Costco data loader processes `./data/costco/*.yaml`
3. **11:40 PM EST**: Walmart data loader processes `./data/walmart/*.yaml`
4. **11:45 PM EST**: Publix data loader processes `./data/publix/*.yaml`
5. **11:50 PM EST**: Other purchases loader processes `./data/other/*.yaml`

### **Upsert Logic**
- All loaders use **upsert logic** to prevent duplicates
- Existing records are updated, new records are inserted
- **Idempotent operations** - safe to run multiple times

## ğŸš¨ **Troubleshooting**

### **Common Issues**
1. **Missing Data Files**: CRON jobs will log warnings but continue
2. **Database Connection**: Check secrets and config maps
3. **Resource Limits**: Monitor memory/CPU usage during peak loads
4. **Time Zone**: All schedules use EST (`America/New_York`)

### **Debug Commands**
```bash
# Check CRON job configuration
kubectl describe cronjob cvs-data-loader -n staging

# Check recent job execution
kubectl get jobs -n staging --sort-by=.metadata.creationTimestamp

# View job logs
kubectl logs job/cvs-data-loader-<timestamp> -n staging

# Manual job trigger
kubectl create job --from=cronjob/cvs-data-loader manual-cvs-load -n staging
```

## ğŸ¯ **Benefits**

âœ… **Automated Data Loading**: Daily processing without manual intervention  
âœ… **Environment Separation**: Staging and production databases isolated  
âœ… **Resource Management**: Appropriate resource allocation per environment  
âœ… **Monitoring**: Job history and logging for troubleshooting  
âœ… **GitOps**: ArgoCD manages deployment and configuration  
âœ… **Scalability**: Easy to add new retailers or modify schedules  

This system ensures reliable, automated data loading for the complete 4-retailer grocery data collection system.

## ğŸ§ª **MANUAL TESTING**

### **RUN_MANUAL Section**

You can manually test all data loaders without waiting for the CRON schedule:

#### **Quick Test - All Loaders**
```bash
# Run all data loaders manually
python scripts/run_manual_data_loaders.py

# Verify data was loaded correctly
python scripts/verify_data_loaded.py --detailed
```

#### **Test Specific Loader**
```bash
# Test individual loaders
python scripts/run_manual_data_loaders.py --loader cvs
python scripts/run_manual_data_loaders.py --loader costco
python scripts/run_manual_data_loaders.py --loader walmart
python scripts/run_manual_data_loaders.py --loader publix
python scripts/run_manual_data_loaders.py --loader other
```

#### **Environment-Specific Testing**
```bash
# Test staging environment
python scripts/run_manual_data_loaders.py --staging
python scripts/verify_data_loaded.py --staging --detailed

# Test production environment
python scripts/run_manual_data_loaders.py --production
python scripts/verify_data_loaded.py --production --detailed
```

#### **Verification Only**
```bash
# Only verify data, don't run loaders
python scripts/run_manual_data_loaders.py --verify-only

# Export verification results
python scripts/verify_data_loaded.py --export --detailed
```

### **Manual Testing Scripts**

- **`scripts/run_manual_data_loaders.py`**: Runs all data loaders manually
- **`scripts/verify_data_loaded.py`**: Verifies data loading results
- **`docs/README_MANUAL_TESTING.md`**: Complete manual testing guide

### **Expected Results**
```
ğŸ‰ MANUAL DATA LOADERS TEST SUMMARY
============================================================
ğŸ“Š LOADER RESULTS:
   CVS     : âœ… SUCCESS (2.34s)
   Costco  : âœ… SUCCESS (3.21s)
   Walmart : âœ… SUCCESS (1.87s)
   Publix  : âœ… SUCCESS (4.12s)
   Other   : âœ… SUCCESS (0.95s)

ğŸ” DATA VERIFICATION:
   CVS     : âœ… 25 records
   Costco  : âœ… 45 records
   Walmart : âœ… 18 records
   Publix  : âœ… 32 records
   Other   : âœ… 12 records

ğŸ“ˆ OVERALL RESULTS:
   âœ… Successful loaders: 5/5
   ğŸ“Š Total records: 132

ğŸ‰ ALL TESTS PASSED! Data loading system is working correctly.
```

### **Troubleshooting Manual Tests**

#### **Missing Data Directories**
```bash
# Ensure data directories exist
ls -la data/cvs/ data/costco/ data/walmart/ data/publix/ data/other/
```

#### **Database Issues**
```bash
# Test database connectivity
python scripts/verify_data_loaded.py --detailed
```

#### **Verbose Debugging**
```bash
# Enable detailed logging
python scripts/run_manual_data_loaders.py --verbose
```

**ğŸ“š Complete Manual Testing Guide**: See `docs/README_MANUAL_TESTING.md` for comprehensive testing instructions.
